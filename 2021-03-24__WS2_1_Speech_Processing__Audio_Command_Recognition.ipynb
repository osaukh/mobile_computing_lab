{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-03-24 WS2_1 Speech Processing: Audio Command Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on the [Simple audio recognition: Recognizing keywords](https://www.tensorflow.org/tutorials/audio/simple_audio) tutorial by TensorFlow but makes it also work on a mobile phone. It shows how to build and run a simple speech recognition TF model. Once you’ve completed this tutorial, you’ll have a application that tries to classify a one second audio clip as either silence, an unknown word, “yes”, “no”, “up”, “down”, “left”, “right”, “on”, “off”, “stop”, or “go”.\n",
    "\n",
    "<img src=\"data:image/png;base64,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\" width=\"250\">\n",
    "\n",
    "* <a href=\"https://github.com/EN10/SimpleSpeech/tree/master/test\"><b>Pre-trained Model</b></a>\n",
    "* <a href=\"https://www.tensorflow.org/tutorials/audio_recognition\"><b>Model Code and Tutorial</b></a>\n",
    "* <a href=\"https://github.com/Thumar/audio-recognition\"><b>App Source Code</b></a>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Follow the TensorFlow tutorial</b>:\n",
    "<ul><li>Use Google Colab: <a href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb\">Simple audio recognition: Recognizing keywords</a></li></ul>\n",
    "</div>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/audio/simple_audio\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/audio/simple_audio.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building / Training / Testing a Model\n",
    "\n",
    "You can train your model on your laptop, or on a server, and then use that pre-trained model on our mobile device. Alternatively, you can use an already <a href=\"http://download.tensorflow.org/models/speech_commands_v0.01.zip\">pre-trained model</a>.\n",
    "\n",
    "\n",
    "## 2. Android App\n",
    "\n",
    "Android <a href=\"https://github.com/Thumar/audio-recognition\">app source code</a>. You need to copy model files to the assets folder and specify correct paths in MainActivity.java.\n",
    "\n",
    "To request microphone, you should be requesting RECORD_AUDIO permission in your manifest file as below:\n",
    "\n",
    "```XML\n",
    "<uses-permission android:name=\"android.permission.RECORD_AUDIO\"/>\n",
    "```\n",
    "\n",
    "#### Microphone Permission\n",
    "\n",
    "Since Android 6.0 Marshmallow, the application will not be granted any permission at installation time. Instead, the application has to ask the user for a permission one-by-one at runtime.\n",
    "\n",
    "```Java\n",
    "private void requestMicrophonePermission() {\n",
    "        ActivityCompat.requestPermissions(MainActivity.this,\n",
    "                new String[]{android.Manifest.permission.RECORD_AUDIO}, REQUEST_RECORD_AUDIO);\n",
    "    }\n",
    "@Override\n",
    "public void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) {\n",
    "      if (requestCode == REQUEST_RECORD_AUDIO&& grantResults.length > 0\n",
    "                && grantResults[0] == PackageManager.PERMISSION_GRANTED) {\n",
    "            startRecording();\n",
    "            startRecognition();\n",
    "      }\n",
    " }\n",
    "```\n",
    "\n",
    "#### Recording Audio\n",
    "\n",
    "The AudioRecord class manages the audio resources for Java applications to record audio from the audio input hardware of the platform. This is achieved by “pulling” (reading) the data from the AudioRecord object. The application is responsible for polling the AudioRecord object in time using read(short[], int, int).\n",
    "\n",
    "```Java\n",
    "private void record() {\n",
    "        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n",
    " \n",
    "        // Estimate the buffer size we'll need for this device.\n",
    "        int bufferSize =\n",
    "                AudioRecord.getMinBufferSize(\n",
    "                        SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);\n",
    "        if (bufferSize == AudioRecord.ERROR || bufferSize == AudioRecord.ERROR_BAD_VALUE) {\n",
    "            bufferSize = SAMPLE_RATE * 2;\n",
    "        }\n",
    "        short[] audioBuffer = new short[bufferSize / 2];\n",
    " \n",
    "        AudioRecord record =\n",
    "                new AudioRecord(\n",
    "                        MediaRecorder.AudioSource.DEFAULT,\n",
    "                        SAMPLE_RATE,\n",
    "                        AudioFormat.CHANNEL_IN_MONO,\n",
    "                        AudioFormat.ENCODING_PCM_16BIT,\n",
    "                        bufferSize);\n",
    " \n",
    "        if (record.getState() != AudioRecord.STATE_INITIALIZED) {\n",
    "            Log.e(LOG_TAG, \"Audio Record can't initialize!\");\n",
    "            return;\n",
    "        }\n",
    " \n",
    "        record.startRecording();\n",
    " \n",
    "        Log.v(LOG_TAG, \"Start recording\");\n",
    " \n",
    "        // Loop, gathering audio data and copying it to a round-robin buffer.\n",
    "        while (shouldContinue) {\n",
    "            int numberRead = record.read(audioBuffer, 0, audioBuffer.length);\n",
    "            int maxLength = recordingBuffer.length;\n",
    "            int newRecordingOffset = recordingOffset + numberRead;\n",
    "            int secondCopyLength = Math.max(0, newRecordingOffset - maxLength);\n",
    "            int firstCopyLength = numberRead - secondCopyLength;\n",
    "            // We store off all the data for the recognition thread to access. The ML\n",
    "            // thread will copy out of this buffer into its own, while holding the\n",
    "            // lock, so this should be thread safe.\n",
    "            recordingBufferLock.lock();\n",
    "            try {\n",
    "                System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, firstCopyLength);\n",
    "                System.arraycopy(audioBuffer, firstCopyLength, recordingBuffer, 0, secondCopyLength);\n",
    "                recordingOffset = newRecordingOffset % maxLength;\n",
    "            } finally {\n",
    "                recordingBufferLock.unlock();\n",
    "            }\n",
    "        }\n",
    " \n",
    "        record.stop();\n",
    "        record.release();\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Run TensorFlow Model\n",
    "\n",
    "A TensorFlowInferenceInterface class that provides a smaller API surface suitable for inference and summarizing the performance of model execution.\n",
    "\n",
    "```Java\n",
    "private void recognize() {\n",
    "    Log.v(LOG_TAG, \"Start recognition\");\n",
    " \n",
    "    short[] inputBuffer = new short[RECORDING_LENGTH];\n",
    "    float[] floatInputBuffer = new float[RECORDING_LENGTH];\n",
    "    float[] outputScores = new float[labels.size()];\n",
    "    String[] outputScoresNames = new String[]{OUTPUT_SCORES_NAME};\n",
    "    int[] sampleRateList = new int[]{SAMPLE_RATE};\n",
    " \n",
    "    // Loop, grabbing recorded data and running the recognition model on it.\n",
    "    while (shouldContinueRecognition) {\n",
    "            // The recording thread places data in this round-robin buffer, so lock to\n",
    "            // make sure there's no writing happening and then copy it to our own\n",
    "            // local version.\n",
    "       recordingBufferLock.lock();\n",
    "       try {\n",
    "           int maxLength = recordingBuffer.length;\n",
    "           int firstCopyLength = maxLength - recordingOffset;\n",
    "           int secondCopyLength = recordingOffset;\n",
    "           System.arraycopy(recordingBuffer, recordingOffset, inputBuffer, 0, firstCopyLength);\n",
    "           System.arraycopy(recordingBuffer, 0, inputBuffer, firstCopyLength, secondCopyLength);\n",
    "        } finally {\n",
    "           recordingBufferLock.unlock();\n",
    "         }\n",
    " \n",
    "            // We need to feed in float values between -1.0f and 1.0f, so divide the\n",
    "            // signed 16-bit inputs.\n",
    "         for (int i = 0; i < RECORDING_LENGTH; ++i) {\n",
    "             floatInputBuffer[i] = inputBuffer[i] / 32767.0f;\n",
    "         }\n",
    " \n",
    "            // Run the model.\n",
    "       inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);\n",
    "       inferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1);\n",
    "       inferenceInterface.run(outputScoresNames);\n",
    "       inferenceInterface.fetch(OUTPUT_SCORES_NAME, outputScores);\n",
    " \n",
    "       // Use the smoother to figure out if we've had a real recognition event.\n",
    "       long currentTime = System.currentTimeMillis();\n",
    "       final RecognizeCommands.RecognitionResult result = recognizeCommands.processLatestResults(outputScores, currentTime);\n",
    " \n",
    "       runOnUiThread(\n",
    "             new Runnable() {\n",
    "                 @Override\n",
    "                 public void run() {\n",
    "                   // If we do have a new command, highlight the right list entry.\n",
    "                      if (!result.foundCommand.startsWith(\"_\") && result.isNewCommand) {\n",
    "                            int labelIndex = -1;\n",
    "                            for (int i = 0; i < labels.size(); ++i) {\n",
    "                             if (labels.get(i).equals(result.foundCommand)) {\n",
    "                                    labelIndex = i;\n",
    "                              }\n",
    "                         }\n",
    "                         label.setText(result.foundCommand);\n",
    "                    }\n",
    "                }\n",
    "              });\n",
    "        try {\n",
    "            // We don't need to run too frequently, so snooze for a bit.\n",
    "            Thread.sleep(MINIMUM_TIME_BETWEEN_SAMPLES_MS);\n",
    "        } catch (InterruptedException e) {\n",
    "         // Ignore\n",
    "        }\n",
    "    }\n",
    " \n",
    "    Log.v(LOG_TAG, \"End recognition\");\n",
    "}\n",
    "```\n",
    "\n",
    "#### Recognize Commands\n",
    "RecognizeCommands class is fed the output of running the TensorFlow model over time, it averages the signals and returns information about a label when it has enough evidence to think that a recognized word has been found. The implementation is fairly small, just keeping track of the last few predictions and averaging them.\n",
    "\n",
    "```Java\n",
    "public RecognitionResult processLatestResults(float[] currentResults, long currentTimeMS) {\n",
    "        if (currentResults.length != labelsCount) {\n",
    "            throw new RuntimeException(\n",
    "                    \"The results for recognition should contain \"\n",
    "                            + labelsCount\n",
    "                            + \" elements, but there are \"\n",
    "                            + currentResults.length);\n",
    "        }\n",
    " \n",
    "        if ((!previousResults.isEmpty()) && (currentTimeMS < previousResults.getFirst().first)) {\n",
    "            throw new RuntimeException(\n",
    "                    \"You must feed results in increasing time order, but received a timestamp of \"\n",
    "                            + currentTimeMS\n",
    "                            + \" that was earlier than the previous one of \"\n",
    "                            + previousResults.getFirst().first);\n",
    "        }\n",
    " \n",
    "        final int howManyResults = previousResults.size();\n",
    "        // Ignore any results that are coming in too frequently.\n",
    "        if (howManyResults > 1) {\n",
    "            final long timeSinceMostRecent = currentTimeMS - previousResults.getLast().first;\n",
    "            if (timeSinceMostRecent < minimumTimeBetweenSamplesMs) {\n",
    "                return new RecognitionResult(previousTopLabel, previousTopLabelScore, false);\n",
    "            }\n",
    "        }\n",
    " \n",
    "        // Add the latest results to the head of the queue.\n",
    "        previousResults.addLast(new Pair<Long, float[]>(currentTimeMS, currentResults));\n",
    "        Log.d(TAG, currentResults + \" \" + currentTimeMS);\n",
    " \n",
    "        // Prune any earlier results that are too old for the averaging window.\n",
    "        final long timeLimit = currentTimeMS - averageWindowDurationMs;\n",
    "        while (previousResults.getFirst().first < timeLimit) {\n",
    "            previousResults.removeFirst();\n",
    "        }\n",
    "        // If there are too few results, assume the result will be unreliable and\n",
    "        // bail.\n",
    "        final long earliestTime = previousResults.getFirst().first;\n",
    "        final long samplesDuration = currentTimeMS - earliestTime;\n",
    "        if ((howManyResults < minimumCount)\n",
    "                || (samplesDuration < (averageWindowDurationMs / MINIMUM_TIME_FRACTION))) {\n",
    "            Log.v(\"RecognizeResult\", \"Too few results\");\n",
    "            return new RecognitionResult(previousTopLabel, 0.0f, false);\n",
    "        }\n",
    " \n",
    "        // Calculate the average score across all the results in the window.\n",
    "        float[] averageScores = new float[labelsCount];\n",
    "        for (Pair<Long, float[]> previousResult : previousResults) {\n",
    "            final float[] scoresTensor = previousResult.second;\n",
    "            int i = 0;\n",
    "            while (i < scoresTensor.length) {\n",
    "                averageScores[i] += scoresTensor[i] / howManyResults;\n",
    "                ++i;\n",
    "            }\n",
    "        }\n",
    " \n",
    "        // Sort the averaged results in descending score order.\n",
    "        ScoreForSorting[] sortedAverageScores = new ScoreForSorting[labelsCount];\n",
    "        for (int i = 0; i < labelsCount; ++i) {\n",
    "            sortedAverageScores[i] = new ScoreForSorting(averageScores[i], i);\n",
    "        }\n",
    "        Arrays.sort(sortedAverageScores);\n",
    " \n",
    "        // See if the latest top score is enough to trigger a detection.\n",
    "        final int currentTopIndex = sortedAverageScores[0].index;\n",
    "        final String currentTopLabel = labels.get(currentTopIndex);\n",
    "        final float currentTopScore = sortedAverageScores[0].score;\n",
    "        // If we've recently had another label trigger, assume one that occurs too\n",
    "        // soon afterwards is a bad result.\n",
    "        long timeSinceLastTop;\n",
    "        if (previousTopLabel.equals(SILENCE_LABEL) || (previousTopLabelTime == Long.MIN_VALUE)) {\n",
    "            timeSinceLastTop = Long.MAX_VALUE;\n",
    "        } else {\n",
    "            timeSinceLastTop = currentTimeMS - previousTopLabelTime;\n",
    "        }\n",
    "        boolean isNewCommand;\n",
    "        if ((currentTopScore > detectionThreshold) && (timeSinceLastTop > suppressionMs)) {\n",
    "            previousTopLabel = currentTopLabel;\n",
    "            previousTopLabelTime = currentTimeMS;\n",
    "            previousTopLabelScore = currentTopScore;\n",
    "            isNewCommand = true;\n",
    "        } else {\n",
    "            isNewCommand = false;\n",
    "        }\n",
    "        return new RecognitionResult(currentTopLabel, currentTopScore, isNewCommand);\n",
    "    }\n",
    "```\n",
    "\n",
    "The demo app updates its UI of results automatically based on the labels text file you copy into assets alongside your frozen graph, which means you can easily try out different models without needing to make any code changes. You will need to update LABEL_FILENAME and MODEL_FILENAME to point to the files you’ve added if you change the paths though.\n",
    "\n",
    "You can easily replace it with a model you’ve trained yourself. If you do this, you’ll need to make sure that the constants in the main MainActivity Java source file like SAMPLE_RATE and SAMPLE_DURATION match any changes you’ve made to the defaults while training. You’ll also see that there’s a Java version of the RecognizeCommands module that’s very similar to the C++ version in this tutorial. If you’ve tweaked parameters for that, you can also update them in MainActivity to get the same results as in your server testing.\n",
    "\n",
    "\n",
    "***\n",
    "## Related Examples and Useful Links\n",
    "\n",
    "* <a href=\"https://medium.com/iotforall/sound-classification-with-tensorflow-8209bdb03dfb\">Sound Classification with TensorFlow</a>\n",
    "* <a href=\"https://www.codementor.io/vishnu_ks/audio-classification-using-image-classification-techniques-hx63anbx1\">Audio classification using Image classification techniques</a>\n",
    "\n",
    "\n",
    "***\n",
    "## Credits\n",
    "* <a href=\"https://www.tensorflow.org/tutorials/audio_recognition\">Simple Audio Recognition</a>\n",
    "* <a href=\"http://androidkt.com/speech-recognition-using-tensorflow/\">Speech Recognition Using TensorFlow</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
