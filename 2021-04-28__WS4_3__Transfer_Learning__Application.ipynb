{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-04-28 WS4_3 Transfer Learning - Android Application\n",
    "\n",
    "<mark>To be updated!</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>This tutorial is based on:</b>\n",
    "<ul><li>\n",
    "<a href=\"https://aqibsaeed.github.io/on-device-activity-recognition#blogpost\">On-device Activity Recognition</a> by Aaqib Saeed\n",
    "</li></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now focus on developing an Android app that can use the generated model in earlier steps for fine-tuning, inference, and data collection. The app does not require access to the internet and works completely offline, resulting in improved user privacy. Let's create a new Android project or start from the one provided here. To start, copy the five model files under a folder named model within the <code>assets</code> directory of the project. In <code>AndroidManifest.xml</code> file copy the below lines, this will give our app access to the accelerometer/vibration, and reading/writing model files. The included <code>transfer_api</code> library has all the required functionality for performing on-device machine learning.\n",
    "\n",
    "```Java\n",
    "< uses-feature android:name=\"android.hardware.sensor.accelerometer\" android:required=\"true\" />\n",
    "< uses-permission android:name=\"android.permission.VIBRATE\" />\n",
    "< uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n",
    "```\n",
    "\n",
    "Importantly, in <code>build.gradle</code> file we need to add the following dependency to use custom Keras model implementation <code>'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'</code>.\n",
    "\n",
    "If you run the [app](https://github.com/osaukh/mobile_computing_lab/tree/master/code/OnDeviceActivityRecognition) on your device it looks like this:\n",
    "\n",
    "<img src=\"https://aqibsaeed.github.io/img/par_app_scrn.png\" width=\"200\">\n",
    "\n",
    "In the <code>TansferLearningModelWrapper.java</code> we specify our model directory name within assets folder:\n",
    "\n",
    "```Java\n",
    "model = new TransferLearningModel(new AssetModelLoader(context, \"model\"), Arrays.asList(\"Class A\", \"Class B\"));\n",
    "```\n",
    "\n",
    "In <code>TansferLearningModelWrapper</code>, we add two additional methods in to save and reload the model:\n",
    "\n",
    "```Java\n",
    "public void saveModel(File file){\n",
    "\ttry {\n",
    "\t\tFileOutputStream out = new FileOutputStream(file);\n",
    "\t\tGatheringByteChannel gather = out.getChannel();\n",
    "\t\tmodel.saveParameters(gather);\n",
    "\t} catch (FileNotFoundException e) {\n",
    "\t\te.printStackTrace();\n",
    "\t} catch (IOException e) {\n",
    "\t\te.printStackTrace();\n",
    "\t}\n",
    "}\n",
    "\n",
    "public void loadModel(File file){\n",
    "\ttry {\n",
    "\t\tFileInputStream inp = new FileInputStream(file);\n",
    "\t\tScatteringByteChannel scatter = inp.getChannel();\n",
    "\t\tmodel.loadParameters(scatter);\n",
    "\t} catch (FileNotFoundException e) {\n",
    "\t\te.printStackTrace();\n",
    "\t} catch (IOException e) {\n",
    "\t\te.printStackTrace();\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "In the <code>MainActivity.java</code> file, we add functionality to glue everything together from, data collection to training and inference directly on the smartphone. The crucial bits are collecting accelerometer data at the highest sampling rate possible and feed into our model when there are 400 values in the buffer. If the data collection mode is selected, we will keep adding instances with their corresponding class ids to the model cache. When we have the required number of instances per class available (which are 5 per category in our case), the training can be initiated. The loss values can be observed fluctuating in the panel as the network is trained. The model can also be saved and reload by uncommenting the respective lines in the source code. During inference, we can observe the output probability of each class in the lower panel. The phone will vibrate if the Class B's probability is above a predefined threshold to make classification process more apparent. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Compile and run the app on an Android device:</b>\n",
    "<ul>\n",
    "<li><a href=\"https://github.com/osaukh/mobile_computing_lab/tree/master/code/OnDeviceActivityRecognition\">Application source code</a></li>\n",
    "<li>Understand the source code!</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
