{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-04-28 WS4_2 Transfer Learning - Head Model\n",
    "\n",
    "<mark>To be updated!</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>This tutorial is based on:</b>\n",
    "<ul><li><a href=\"https://aqibsaeed.github.io/on-device-activity-recognition#blogpost\">On-device Activity Recognition</a> by Aaqib Saeed</li>\n",
    "<li><a href=\"https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/README.md\">TensorFlow Lite Example On-device Model Personalization</a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you remember, we now use a part of the pre-trained generic model (=base model) and add a head model, which will be trained on a mobile device. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*Bi-_rpBbfhVAz6gi1uIRnw.png\" width=\"800\">\n",
    "\n",
    "A head model is typically a simpler network with a few fully-connected (fc) layers. Base model weights are fixed during conversion, and cannot be changed later. Hence with frozen weights in the main network, we will get to use the pre-trained weights to get important feature activations as bottleneck features into our newly added fully-connected network, and now this new fully-connected network (trained on gathered data on a device) gives us the required inference as per training.\n",
    "\n",
    "Clone the <a href=\"https://github.com/osaukh/mobile_computing_lab/tree/master/code/OnDeviceActivityRecognition\">repository</a> containing the converter, the Android library and the example app.\n",
    "\n",
    "Do the following from the converter directory to install <code>tfltransfer</code>:\n",
    "\n",
    "```bash\n",
    "# Create a virtualenv. This step is optional but recommended.\n",
    "virtualenv venv\n",
    "\n",
    "# Activate the created virtualenv.\n",
    "source venv/bin/activate\n",
    "\n",
    "# Install the converter.\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "After training the network for a fixed number of epochs in a standard way, we will save the encoder part of the network named base (without the last layer) in a TensorFlow SavedModel format. The next step is to define a fine-tuning network named head with additional layers that will be trained on a device while keeping the base model fixed. To keep things simple, we add a fully connected layer with 6 units and an output layer with 2 units (for differentiating between two activities). Here, you can also choose between following optimizers <code>Adam</code> or <code>SGD</code> with <code>optimizers.SGD</code> and <code>optimizers.Adam</code>, respectively. Afterward, we will convert and save this network using the __TFLite Transfer Converter__ that will generate the following five files: bottleneck.tflite, inference.tflite, initialize.tflite, optimizer.tflite, and train_head.tflite in a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0410 15:59:10.930770 4549289408 deprecation.py:506] From /Users/ahinea/work/pyenv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0410 15:59:11.218513 4549289408 deprecation.py:323] From /Users/ahinea/work/mobile_computing_lab/code/OnDeviceActivityRecognition/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
      "W0410 15:59:11.535582 4549289408 deprecation.py:323] From /Users/ahinea/work/pyenv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0410 15:59:11.536261 4549289408 export_utils.py:182] Export includes no default signature!\n",
      "W0410 15:59:11.671192 4549289408 export_utils.py:182] Export includes no default signature!\n",
      "W0410 15:59:11.764970 4549289408 deprecation.py:323] From /Users/ahinea/work/mobile_computing_lab/code/OnDeviceActivityRecognition/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "W0410 15:59:11.939062 4549289408 deprecation.py:323] From /Users/ahinea/work/pyenv/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0410 15:59:11.939838 4549289408 deprecation.py:323] From /Users/ahinea/work/pyenv/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0410 15:59:12.026404 4549289408 meta_graph.py:448] Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n",
      "W0410 15:59:12.026903 4549289408 meta_graph.py:448] Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n",
      "W0410 15:59:12.027418 4549289408 meta_graph.py:448] Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n",
      "W0410 15:59:13.833530 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0410 15:59:13.834701 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0410 15:59:13.835896 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0410 15:59:13.836499 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0410 15:59:13.837243 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "W0410 15:59:13.838185 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "W0410 15:59:13.838787 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "W0410 15:59:13.839467 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "W0410 15:59:13.840063 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "W0410 15:59:13.840675 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "W0410 15:59:13.841284 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "W0410 15:59:13.842120 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "W0410 15:59:13.842696 4549289408 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "W0410 15:59:13.846893 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer\n",
      "W0410 15:59:13.847671 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0410 15:59:13.848389 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0410 15:59:13.849101 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0410 15:59:13.849678 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0410 15:59:13.850341 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0410 15:59:13.850955 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "W0410 15:59:13.851662 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "W0410 15:59:13.852263 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "W0410 15:59:13.853104 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "W0410 15:59:13.854218 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "W0410 15:59:13.855360 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "W0410 15:59:13.856246 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "W0410 15:59:13.857190 4549289408 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "W0410 15:59:13.858054 4549289408 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "W0410 15:59:13.951931 4549289408 meta_graph.py:448] Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 15:59:13.952501 4549289408 meta_graph.py:448] Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n",
      "W0410 15:59:13.953075 4549289408 meta_graph.py:448] Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "to_proto not supported in EAGER mode.\n",
      "/Users/ahinea/work/pyenv/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
      "  \"target_spec.supported_ops instead.\" % name)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tfltransfer import bases\n",
    "from tfltransfer import heads\n",
    "from tfltransfer import optimizers\n",
    "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
    "\n",
    "model_m = load_model('ws4_tl/saved_model.pbtxt')\n",
    "model = Model(model_m.input, model_m.get_layer('headlayer').output)\n",
    "save_model(model, 'ws4_tl/chopped_model.pbtxt', include_optimizer = False,save_format=\"tf\")\n",
    "\n",
    "# --------------- on-device model conversion ---------------- #\n",
    "\n",
    "# Model configuration.\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 5\n",
    "l2_rate = 0.0001\n",
    "hidden_units = 6\n",
    "input_shape = model.get_layer('headlayer').output.shape\n",
    "\n",
    "\n",
    "base = bases.SavedModelBase('ws4_tl/chopped_model.pbtxt')\n",
    "head = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=(1, 80, 8)),\n",
    "    layers.Dense(\n",
    "        units=hidden_units,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=l2(l2_rate)),\n",
    "    layers.Dense(\n",
    "        units=num_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=l2(l2_rate)),\n",
    "])\n",
    "\n",
    "# Optimizer is ignored by the converter.\n",
    "head.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "converter = TFLiteTransferConverter(num_classes,\n",
    "                base,\n",
    "                heads.KerasModelHead(head),\n",
    "                optimizers.SGD(learning_rate),\n",
    "                train_batch_size=batch_size)\n",
    "\n",
    "converter.convert_and_save('ws4_tl/custom_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
