{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WS04--TransferLearning--Personalization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSmXxvjTyv3z",
        "outputId": "c5b1bbc7-cf0b-42f1-ab5e-e4fde55a94e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# tensorflow>=2.7.*\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"CLI wrapper for tflite_transfer_converter.\n",
        "\n",
        "Converts a TF model to a TFLite transfer learning model.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NUM_FEATURES = 7 * 7 * 1280\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "\n",
        "class TransferLearningModel(tf.Module):\n",
        "  \"\"\"TF Transfer Learning model class.\"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate=0.001):\n",
        "    \"\"\"Initializes a transfer learning model instance.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: A learning rate for the optimzer.\n",
        "    \"\"\"\n",
        "    self.num_features = NUM_FEATURES\n",
        "    self.num_classes = NUM_CLASSES\n",
        "\n",
        "    # trainable weights and bias for softmax\n",
        "    self.ws = tf.Variable(\n",
        "        tf.zeros((self.num_features, self.num_classes)),\n",
        "        name='ws',\n",
        "        trainable=True)\n",
        "    self.bs = tf.Variable(\n",
        "        tf.zeros((1, self.num_classes)), name='bs', trainable=True)\n",
        "\n",
        "    # base model\n",
        "    self.base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        alpha=1.0,\n",
        "        include_top=False,\n",
        "        weights='imagenet')\n",
        "    # loss function and optimizer\n",
        "    self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
        "  ])\n",
        "  def load(self, feature):\n",
        "    \"\"\"Generates and loads bottleneck features from the given image batch.\n",
        "\n",
        "    Args:\n",
        "      feature: A tensor of image feature batch to generate the bottleneck from.\n",
        "\n",
        "    Returns:\n",
        "      Map of the bottleneck.\n",
        "    \"\"\"\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        tf.multiply(feature, 255))\n",
        "    bottleneck = tf.reshape(\n",
        "        self.base(x, training=False), (-1, self.num_features))\n",
        "    return {'bottleneck': bottleneck}\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec([None, NUM_FEATURES], tf.float32),\n",
        "      tf.TensorSpec([None, NUM_CLASSES], tf.float32),\n",
        "  ])\n",
        "  def train(self, bottleneck, label):\n",
        "    \"\"\"Runs one training step with the given bottleneck features and labels.\n",
        "\n",
        "    Args:\n",
        "      bottleneck: A tensor of bottleneck features generated from the base model.\n",
        "      label: A tensor of class labels for the given batch.\n",
        "\n",
        "    Returns:\n",
        "      Map of the training loss.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
        "      prediction = tf.nn.softmax(logits)\n",
        "      loss = self.loss_fn(prediction, label)\n",
        "    gradients = tape.gradient(loss, [self.ws, self.bs])\n",
        "    self.optimizer.apply_gradients(zip(gradients, [self.ws, self.bs]))\n",
        "    result = {'loss': loss}\n",
        "    for grad in gradients:\n",
        "      result[grad.name] = grad\n",
        "    return result\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32)\n",
        "  ])\n",
        "  def infer(self, feature):\n",
        "    \"\"\"Invokes an inference on the given feature.\n",
        "\n",
        "    Args:\n",
        "      feature: A tensor of image feature batch to invoke an inference on.\n",
        "\n",
        "    Returns:\n",
        "      Map of the softmax output.\n",
        "    \"\"\"\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        tf.multiply(feature, 255))\n",
        "    bottleneck = tf.reshape(\n",
        "        self.base(x, training=False), (-1, self.num_features))\n",
        "    logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
        "    return {'output': tf.nn.softmax(logits)}\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[], dtype=tf.string)\n",
        "  ])\n",
        "  def save(self, checkpoint_path):\n",
        "    \"\"\"Saves the trainable weights to the given checkpoint file.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_path: A file path to save the model.\n",
        "\n",
        "    Returns:\n",
        "      Map of the checkpoint file path.\n",
        "    \"\"\"\n",
        "    tensor_names = [self.ws.name, self.bs.name]\n",
        "    tensors_to_save = [self.ws.read_value(), self.bs.read_value()]\n",
        "    tf.raw_ops.Save(\n",
        "        filename=checkpoint_path,\n",
        "        tensor_names=tensor_names,\n",
        "        data=tensors_to_save,\n",
        "        name='save')\n",
        "    return {'checkpoint_path': checkpoint_path}\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[], dtype=tf.string)\n",
        "  ])\n",
        "  def restore(self, checkpoint_path):\n",
        "    \"\"\"Restores the serialized trainable weights from the given checkpoint file.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_path: A path to a saved checkpoint file.\n",
        "\n",
        "    Returns:\n",
        "      Map of restored weight and bias.\n",
        "    \"\"\"\n",
        "    restored_tensors = {}\n",
        "    restored = tf.raw_ops.Restore(\n",
        "        file_pattern=checkpoint_path,\n",
        "        tensor_name=self.ws.name,\n",
        "        dt=np.float32,\n",
        "        name='restore')\n",
        "    self.ws.assign(restored)\n",
        "    restored_tensors['ws'] = restored\n",
        "    restored = tf.raw_ops.Restore(\n",
        "        file_pattern=checkpoint_path,\n",
        "        tensor_name=self.bs.name,\n",
        "        dt=np.float32,\n",
        "        name='restore')\n",
        "    self.bs.assign(restored)\n",
        "    restored_tensors['bs'] = restored\n",
        "    return restored_tensors\n",
        "\n",
        "  @tf.function(input_signature=[])\n",
        "  def initialize_weights(self):\n",
        "    \"\"\"Initializes the weights and bias of the head model.\n",
        "\n",
        "    Returns:\n",
        "      Map of initialized weight and bias.\n",
        "    \"\"\"\n",
        "    self.ws.assign(tf.random.uniform((self.num_features, self.num_classes)))\n",
        "    self.bs.assign(tf.random.uniform((1, self.num_classes)))\n",
        "    return {'ws': self.ws, 'bs': self.bs}\n",
        "\n",
        "\n",
        "def convert_and_save(saved_model_dir='saved_model'):\n",
        "  \"\"\"Converts and saves the TFLite Transfer Learning model.\n",
        "\n",
        "  Args:\n",
        "    saved_model_dir: A directory path to save a converted model.\n",
        "  \"\"\"\n",
        "  model = TransferLearningModel()\n",
        "\n",
        "  tf.saved_model.save(\n",
        "      model,\n",
        "      saved_model_dir,\n",
        "      signatures={\n",
        "          'load': model.load.get_concrete_function(),\n",
        "          'train': model.train.get_concrete_function(),\n",
        "          'infer': model.infer.get_concrete_function(),\n",
        "          'save': model.save.get_concrete_function(),\n",
        "          'restore': model.restore.get_concrete_function(),\n",
        "          'initialize': model.initialize_weights.get_concrete_function(),\n",
        "      })\n",
        "\n",
        "  # Convert the model\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "  converter.target_spec.supported_ops = [\n",
        "      tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
        "      tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
        "  ]\n",
        "  converter.experimental_enable_resource_variables = True\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  model_file_path = os.path.join('model.tflite')\n",
        "  with open(model_file_path, 'wb') as model_file:\n",
        "    model_file.write(tflite_model)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  convert_and_save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKL2AbFny6To",
        "outputId": "bf0c3029-55a7-4103-da37-2152b075ef02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_81162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_81178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fcj1SAGwzJoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}